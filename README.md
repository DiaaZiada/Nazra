[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DiaaZiada/Nazra/blob/master/NazRa.ipynb)

# Nazra
Deep Learning for Hand Pose Estimation

## Description
we will be building a Real Time Hand Tracking System that can work on phones in the background to capture the preceise position of our hands and send this to the VR environment for all kind of interactions and cool stuff :)

This project was inspired from the great company [Leap Motion](https://www.leapmotion.com/) and their project [North Star](https://developer.leapmotion.com/northstar) ... and we hope to help them make the world a better place.

<p align="center">
   <a href="https://www.youtube.com/watch?v=7m6J8W6Ib4w"><img src="https://img.youtube.com/vi/7m6J8W6Ib4w/0.jpg"></a>
</p>

## Research
- [Hand Pose Estimation: A Survey](https://arxiv.org/abs/1903.01013v1)
- [V2V-PoseNet: Voxel-to-Voxel Prediction Network for Accurate 3D Hand Pose Estimation](https://arxiv.org/abs/1711.07399v3)
- [Real-time Hand Tracking under Occlusion from an Egocentric RGB-D Sensor](https://arxiv.org/abs/1704.02201v2)
- [Real-time Hand Gesture Detection and Classification Using Convolutional Neural Networks](https://arxiv.org/abs/1901.10323v2)

## Deployment
**To be Continued**

